{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6f76124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostRegressor\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import optuna\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08f86bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('datafinal.csv')\n",
    "data=data.drop(['t2mshan', 'sh850ct', 'sh700ct', 'u700ct', 'vo850ct', 'sktshan', 't2msib', 'u850ct', 'stct', 'rh700ct', 'sktsib', 'dz850sib', 'sstct', 'mslpsib', 'rh925ct', 'rh850ct', 'z850sib', 'sst', 'vo925ct', 'rh850', 'spsib', 'st', 'u925ct', 'u925', 'sh925ct', 'dmslpsib', 'dspsib', 'sh850', 'dspct', 'dz925sib', 'sh700', 'dmslpct', 'z925sib'],axis=1)\n",
    "data.set_index('date', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6189196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukuran data pelatihan yang telah diacak: (38185, 41)\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.8 * len(data))\n",
    "\n",
    "y_train = data['cens'][:train_size]\n",
    "X_train = data.drop('cens',axis=1)[:train_size]\n",
    "y_test = data['cens'][train_size:]\n",
    "X_test = data.drop('cens',axis=1)[train_size:]\n",
    "\n",
    "target = data['cens']\n",
    "feature = data.drop('cens',axis=1)\n",
    "\n",
    "print(\"Ukuran data pelatihan yang telah diacak:\", X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b4854d",
   "metadata": {},
   "source": [
    "Define HyperParameter Search and define optuna objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b70188df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 00:05:13,011]\u001b[0m A new study created in memory with name: no-name-59978b39-5afa-40d0-9116-46b99d983610\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:05:36,572]\u001b[0m Trial 0 finished with value: 0.796433863360532 and parameters: {'n_estimators': 1345, 'max_depth': 10, 'learning_rate': 0.0467324007884916, 'subsample': 0.9068239285519033, 'reg_alpha': 0.8358103729425416, 'reg_lambda': 0.975093971737965, 'colsample_bytree': 0.727271935933674, 'min_child_samples': 12}. Best is trial 0 with value: 0.796433863360532.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:05:52,628]\u001b[0m Trial 1 finished with value: 0.7565913976452551 and parameters: {'n_estimators': 913, 'max_depth': 8, 'learning_rate': 0.003032445725667352, 'subsample': 0.8815970333565266, 'reg_alpha': 0.2666566089691801, 'reg_lambda': 0.49332809644525977, 'colsample_bytree': 0.6326154194550753, 'min_child_samples': 9}. Best is trial 0 with value: 0.796433863360532.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:06:49,575]\u001b[0m Trial 2 finished with value: 0.7997028239360231 and parameters: {'n_estimators': 3335, 'max_depth': 9, 'learning_rate': 0.06078954060115682, 'subsample': 0.7332762903690933, 'reg_alpha': 0.9718712140672601, 'reg_lambda': 0.8284639542267409, 'colsample_bytree': 0.8997949649585618, 'min_child_samples': 11}. Best is trial 2 with value: 0.7997028239360231.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:07:44,219]\u001b[0m Trial 3 finished with value: 0.7947256005668564 and parameters: {'n_estimators': 4715, 'max_depth': 5, 'learning_rate': 0.085112430314018, 'subsample': 0.9377811658372477, 'reg_alpha': 0.37864396148299484, 'reg_lambda': 0.6757490927927218, 'colsample_bytree': 0.6603381373978856, 'min_child_samples': 12}. Best is trial 2 with value: 0.7997028239360231.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:07:48,593]\u001b[0m Trial 4 finished with value: 0.7932295326781605 and parameters: {'n_estimators': 635, 'max_depth': 3, 'learning_rate': 0.030679978187447023, 'subsample': 0.9118719351336545, 'reg_alpha': 0.3637686238076291, 'reg_lambda': 0.028303085217523893, 'colsample_bytree': 0.6706084887180424, 'min_child_samples': 4}. Best is trial 2 with value: 0.7997028239360231.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:08:42,374]\u001b[0m Trial 5 finished with value: 0.7972519560646772 and parameters: {'n_estimators': 3834, 'max_depth': 5, 'learning_rate': 0.05408486717176793, 'subsample': 0.7504360790258231, 'reg_alpha': 0.11071868342032354, 'reg_lambda': 0.46781707074891377, 'colsample_bytree': 0.6487973327878793, 'min_child_samples': 3}. Best is trial 2 with value: 0.7997028239360231.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:08:55,651]\u001b[0m Trial 6 finished with value: 0.7666385130068061 and parameters: {'n_estimators': 949, 'max_depth': 4, 'learning_rate': 0.005002848774214289, 'subsample': 0.5127567009958471, 'reg_alpha': 0.828662748743804, 'reg_lambda': 0.6377133833868041, 'colsample_bytree': 0.8361368376515281, 'min_child_samples': 6}. Best is trial 2 with value: 0.7997028239360231.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:09:08,866]\u001b[0m Trial 7 finished with value: 0.8067059414740994 and parameters: {'n_estimators': 2231, 'max_depth': 2, 'learning_rate': 0.07528667479459197, 'subsample': 0.5510535093147169, 'reg_alpha': 0.722635975977918, 'reg_lambda': 0.6443795981799225, 'colsample_bytree': 0.5557371118363501, 'min_child_samples': 14}. Best is trial 7 with value: 0.8067059414740994.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:09:25,084]\u001b[0m Trial 8 finished with value: 0.8020911067600095 and parameters: {'n_estimators': 1213, 'max_depth': 4, 'learning_rate': 0.09495840264948381, 'subsample': 0.9809847962453181, 'reg_alpha': 0.8872600689811828, 'reg_lambda': 0.4128158394288579, 'colsample_bytree': 0.8865625038724496, 'min_child_samples': 9}. Best is trial 7 with value: 0.8067059414740994.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:10:06,207]\u001b[0m Trial 9 finished with value: 0.7950690466256901 and parameters: {'n_estimators': 3581, 'max_depth': 9, 'learning_rate': 0.06736453082276957, 'subsample': 0.9895495210585579, 'reg_alpha': 0.9247135894258559, 'reg_lambda': 0.48915049821507317, 'colsample_bytree': 0.5694193656529243, 'min_child_samples': 12}. Best is trial 7 with value: 0.8067059414740994.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:10:11,334]\u001b[0m Trial 10 finished with value: 0.7855021689090526 and parameters: {'n_estimators': 1938, 'max_depth': 1, 'learning_rate': 0.08217216924888068, 'subsample': 0.5324329569512768, 'reg_alpha': 0.6573394762848908, 'reg_lambda': 0.27985011814149374, 'colsample_bytree': 0.5306945311597898, 'min_child_samples': 18}. Best is trial 7 with value: 0.8067059414740994.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:10:19,247]\u001b[0m Trial 11 finished with value: 0.7935747492843803 and parameters: {'n_estimators': 2197, 'max_depth': 1, 'learning_rate': 0.09975652834964593, 'subsample': 0.6346003503246039, 'reg_alpha': 0.6746451575120375, 'reg_lambda': 0.21491773624886656, 'colsample_bytree': 0.9922994597964369, 'min_child_samples': 17}. Best is trial 7 with value: 0.8067059414740994.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:10:39,467]\u001b[0m Trial 12 finished with value: 0.7991457447107888 and parameters: {'n_estimators': 2743, 'max_depth': 3, 'learning_rate': 0.0931077230183351, 'subsample': 0.7962409357930242, 'reg_alpha': 0.6472770280514404, 'reg_lambda': 0.6717247633425857, 'colsample_bytree': 0.7904875143412788, 'min_child_samples': 15}. Best is trial 7 with value: 0.8067059414740994.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:10:41,538]\u001b[0m Trial 13 finished with value: 0.7889003963272944 and parameters: {'n_estimators': 116, 'max_depth': 7, 'learning_rate': 0.07472406631821697, 'subsample': 0.6289816509371229, 'reg_alpha': 0.7664889027477438, 'reg_lambda': 0.3459322018638554, 'colsample_bytree': 0.5191499580850203, 'min_child_samples': 8}. Best is trial 7 with value: 0.8067059414740994.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:10:50,520]\u001b[0m Trial 14 finished with value: 0.8040397359115335 and parameters: {'n_estimators': 1628, 'max_depth': 2, 'learning_rate': 0.08547193909126594, 'subsample': 0.996102831693759, 'reg_alpha': 0.9922672103566444, 'reg_lambda': 0.6288030896331973, 'colsample_bytree': 0.7573408652498551, 'min_child_samples': 15}. Best is trial 7 with value: 0.8067059414740994.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:10:58,383]\u001b[0m Trial 15 finished with value: 0.8053787411424914 and parameters: {'n_estimators': 1847, 'max_depth': 2, 'learning_rate': 0.07671342697506378, 'subsample': 0.8508847594568049, 'reg_alpha': 0.6026052559624244, 'reg_lambda': 0.62286139446857, 'colsample_bytree': 0.7316241346216931, 'min_child_samples': 15}. Best is trial 7 with value: 0.8067059414740994.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:11:10,145]\u001b[0m Trial 16 finished with value: 0.8082354163850255 and parameters: {'n_estimators': 2822, 'max_depth': 2, 'learning_rate': 0.07289267457871532, 'subsample': 0.8362101731189066, 'reg_alpha': 0.5294708841147577, 'reg_lambda': 0.8180626444557617, 'colsample_bytree': 0.572137249155041, 'min_child_samples': 20}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:11:34,891]\u001b[0m Trial 17 finished with value: 0.7948980875210738 and parameters: {'n_estimators': 2785, 'max_depth': 6, 'learning_rate': 0.07385685597872167, 'subsample': 0.8159759872518785, 'reg_alpha': 0.5359368781307414, 'reg_lambda': 0.818404310782858, 'colsample_bytree': 0.5861869255382102, 'min_child_samples': 19}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:11:51,335]\u001b[0m Trial 18 finished with value: 0.8063798751182398 and parameters: {'n_estimators': 4557, 'max_depth': 2, 'learning_rate': 0.06458094805185492, 'subsample': 0.6984605331985116, 'reg_alpha': 0.4959847049080813, 'reg_lambda': 0.9785928547461045, 'colsample_bytree': 0.5124558614775969, 'min_child_samples': 20}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:12:07,937]\u001b[0m Trial 19 finished with value: 0.8044894452336628 and parameters: {'n_estimators': 3098, 'max_depth': 3, 'learning_rate': 0.047552790997986316, 'subsample': 0.5540829963360303, 'reg_alpha': 0.7707363350647803, 'reg_lambda': 0.7972842473645367, 'colsample_bytree': 0.5855375180324904, 'min_child_samples': 17}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:12:18,167]\u001b[0m Trial 20 finished with value: 0.7983746065875408 and parameters: {'n_estimators': 4120, 'max_depth': 1, 'learning_rate': 0.08707436723654002, 'subsample': 0.5882751036067189, 'reg_alpha': 0.498022771080854, 'reg_lambda': 0.7476548154900664, 'colsample_bytree': 0.5018856276314722, 'min_child_samples': 1}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:12:34,136]\u001b[0m Trial 21 finished with value: 0.8027866882366264 and parameters: {'n_estimators': 4484, 'max_depth': 2, 'learning_rate': 0.0670464687215876, 'subsample': 0.6862863614227392, 'reg_alpha': 0.5001970198518576, 'reg_lambda': 0.9745218753548885, 'colsample_bytree': 0.5512076401778483, 'min_child_samples': 20}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 00:12:49,126]\u001b[0m Trial 22 finished with value: 0.8017754074620296 and parameters: {'n_estimators': 2404, 'max_depth': 4, 'learning_rate': 0.06213830596977289, 'subsample': 0.687923896923231, 'reg_alpha': 0.5495292971431415, 'reg_lambda': 0.9075264351324628, 'colsample_bytree': 0.5003800679497191, 'min_child_samples': 20}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:13:05,405]\u001b[0m Trial 23 finished with value: 0.8006594865142975 and parameters: {'n_estimators': 4250, 'max_depth': 2, 'learning_rate': 0.07460153064799481, 'subsample': 0.5778964419927335, 'reg_alpha': 0.7293234340668736, 'reg_lambda': 0.8777745795410683, 'colsample_bytree': 0.6082944910074988, 'min_child_samples': 14}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:13:19,737]\u001b[0m Trial 24 finished with value: 0.8038694806403415 and parameters: {'n_estimators': 3099, 'max_depth': 3, 'learning_rate': 0.06834361763675792, 'subsample': 0.5006723417602508, 'reg_alpha': 0.4292147709978317, 'reg_lambda': 0.9132418624965346, 'colsample_bytree': 0.5499088996625773, 'min_child_samples': 17}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:13:32,929]\u001b[0m Trial 25 finished with value: 0.7977045282849736 and parameters: {'n_estimators': 4937, 'max_depth': 1, 'learning_rate': 0.05587297069802004, 'subsample': 0.8008398771768553, 'reg_alpha': 0.5892544483182821, 'reg_lambda': 0.7497967479258368, 'colsample_bytree': 0.6130792678911634, 'min_child_samples': 20}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:14:10,074]\u001b[0m Trial 26 finished with value: 0.7960426365145421 and parameters: {'n_estimators': 2222, 'max_depth': 6, 'learning_rate': 0.08015635427223684, 'subsample': 0.6168653194345834, 'reg_alpha': 0.7081580076456424, 'reg_lambda': 0.5723029185218347, 'colsample_bytree': 0.5475334137121994, 'min_child_samples': 18}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:14:29,207]\u001b[0m Trial 27 finished with value: 0.8041250771640293 and parameters: {'n_estimators': 3762, 'max_depth': 2, 'learning_rate': 0.08897627618372678, 'subsample': 0.6711359766009519, 'reg_alpha': 0.6528416009444244, 'reg_lambda': 0.9753920072016536, 'colsample_bytree': 0.5778342957663392, 'min_child_samples': 14}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:14:59,565]\u001b[0m Trial 28 finished with value: 0.803801723561866 and parameters: {'n_estimators': 2997, 'max_depth': 4, 'learning_rate': 0.07929655467463469, 'subsample': 0.7557538371036208, 'reg_alpha': 0.589042633513063, 'reg_lambda': 0.7495310174626122, 'colsample_bytree': 0.6878936119736401, 'min_child_samples': 16}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:15:07,742]\u001b[0m Trial 29 finished with value: 0.8073711492831146 and parameters: {'n_estimators': 1595, 'max_depth': 3, 'learning_rate': 0.057792226415221255, 'subsample': 0.5445998606893185, 'reg_alpha': 0.5016848671479919, 'reg_lambda': 0.9633901717084055, 'colsample_bytree': 0.612564676588808, 'min_child_samples': 13}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:15:14,770]\u001b[0m Trial 30 finished with value: 0.8045389529875565 and parameters: {'n_estimators': 1288, 'max_depth': 3, 'learning_rate': 0.041923626807902584, 'subsample': 0.5427944664394352, 'reg_alpha': 0.8154810330461111, 'reg_lambda': 0.8631792094068862, 'colsample_bytree': 0.6166817959219848, 'min_child_samples': 13}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:15:25,800]\u001b[0m Trial 31 finished with value: 0.8052683042298305 and parameters: {'n_estimators': 1886, 'max_depth': 2, 'learning_rate': 0.061515049414536366, 'subsample': 0.5773981436349713, 'reg_alpha': 0.45540837465389516, 'reg_lambda': 0.9966663810223343, 'colsample_bytree': 0.531026940155712, 'min_child_samples': 10}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:15:29,521]\u001b[0m Trial 32 finished with value: 0.7803952746492763 and parameters: {'n_estimators': 1500, 'max_depth': 1, 'learning_rate': 0.07122507686407253, 'subsample': 0.5383373861416325, 'reg_alpha': 0.3316272543039066, 'reg_lambda': 0.92430999590689, 'colsample_bytree': 0.6291005253592353, 'min_child_samples': 19}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:15:41,596]\u001b[0m Trial 33 finished with value: 0.802786107994544 and parameters: {'n_estimators': 2575, 'max_depth': 3, 'learning_rate': 0.06408590341795498, 'subsample': 0.6011764055393418, 'reg_alpha': 0.4245354603944422, 'reg_lambda': 0.9351696521109027, 'colsample_bytree': 0.5692773948438634, 'min_child_samples': 11}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:15:44,027]\u001b[0m Trial 34 finished with value: 0.7909170503827265 and parameters: {'n_estimators': 589, 'max_depth': 2, 'learning_rate': 0.05668593097302552, 'subsample': 0.6437558773320577, 'reg_alpha': 0.4907417932845489, 'reg_lambda': 0.8533724360327108, 'colsample_bytree': 0.6035885940774733, 'min_child_samples': 13}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:16:12,405]\u001b[0m Trial 35 finished with value: 0.7967453884732878 and parameters: {'n_estimators': 2227, 'max_depth': 5, 'learning_rate': 0.06921449549978187, 'subsample': 0.7219525995327588, 'reg_alpha': 0.3050969750578967, 'reg_lambda': 0.8059381509393364, 'colsample_bytree': 0.6511305529510102, 'min_child_samples': 16}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:16:34,311]\u001b[0m Trial 36 finished with value: 0.8007309364786153 and parameters: {'n_estimators': 3383, 'max_depth': 4, 'learning_rate': 0.05044736335206944, 'subsample': 0.558567159182922, 'reg_alpha': 0.2567319347602792, 'reg_lambda': 0.9472757537490337, 'colsample_bytree': 0.6848625578088862, 'min_child_samples': 18}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:16:38,278]\u001b[0m Trial 37 finished with value: 0.8036827988863642 and parameters: {'n_estimators': 998, 'max_depth': 3, 'learning_rate': 0.060501729266166746, 'subsample': 0.5100386359851175, 'reg_alpha': 0.5505926132198962, 'reg_lambda': 0.8744547995728681, 'colsample_bytree': 0.5262851330462132, 'min_child_samples': 7}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:16:42,888]\u001b[0m Trial 38 finished with value: 0.78573223535389 and parameters: {'n_estimators': 1748, 'max_depth': 1, 'learning_rate': 0.08040611093384042, 'subsample': 0.5958489643876522, 'reg_alpha': 0.4517781887404569, 'reg_lambda': 0.9996020522240231, 'colsample_bytree': 0.6338874181274895, 'min_child_samples': 10}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:17:21,457]\u001b[0m Trial 39 finished with value: 0.8014030784299586 and parameters: {'n_estimators': 4105, 'max_depth': 5, 'learning_rate': 0.07168004044892294, 'subsample': 0.8888275606431557, 'reg_alpha': 0.6315002051554878, 'reg_lambda': 0.7175403035517954, 'colsample_bytree': 0.5562444416240616, 'min_child_samples': 13}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:17:28,212]\u001b[0m Trial 40 finished with value: 0.8039077088161592 and parameters: {'n_estimators': 662, 'max_depth': 10, 'learning_rate': 0.04156111356302933, 'subsample': 0.564858058326697, 'reg_alpha': 0.3870758305435216, 'reg_lambda': 0.7950758497489541, 'colsample_bytree': 0.5868574722744617, 'min_child_samples': 5}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:17:36,485]\u001b[0m Trial 41 finished with value: 0.8054173301661989 and parameters: {'n_estimators': 1968, 'max_depth': 2, 'learning_rate': 0.07783882058638804, 'subsample': 0.8654865207319696, 'reg_alpha': 0.562237942791162, 'reg_lambda': 0.5928037496285881, 'colsample_bytree': 0.7109050288762209, 'min_child_samples': 15}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:17:47,010]\u001b[0m Trial 42 finished with value: 0.802944613465391 and parameters: {'n_estimators': 2460, 'max_depth': 2, 'learning_rate': 0.06560537846699567, 'subsample': 0.9308512052340074, 'reg_alpha': 0.5763301886404063, 'reg_lambda': 0.5807895119939954, 'colsample_bytree': 0.675263548143602, 'min_child_samples': 12}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:17:50,392]\u001b[0m Trial 43 finished with value: 0.7801720679952577 and parameters: {'n_estimators': 1372, 'max_depth': 1, 'learning_rate': 0.07743522784122975, 'subsample': 0.8604599985922131, 'reg_alpha': 0.5285654415449521, 'reg_lambda': 0.5562605615075583, 'colsample_bytree': 0.6625905526169049, 'min_child_samples': 19}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:18:00,986]\u001b[0m Trial 44 finished with value: 0.8035667285136072 and parameters: {'n_estimators': 2116, 'max_depth': 3, 'learning_rate': 0.08409032117672398, 'subsample': 0.5277515029730342, 'reg_alpha': 0.6961433511154056, 'reg_lambda': 0.6884697777975768, 'colsample_bytree': 0.7003117271800255, 'min_child_samples': 16}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 00:18:10,892]\u001b[0m Trial 45 finished with value: 0.8021719979074163 and parameters: {'n_estimators': 1656, 'max_depth': 4, 'learning_rate': 0.0599878964659873, 'subsample': 0.8266384150605808, 'reg_alpha': 0.6070547098569186, 'reg_lambda': 0.8952713198601993, 'colsample_bytree': 0.6481452396477221, 'min_child_samples': 14}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:18:21,701]\u001b[0m Trial 46 finished with value: 0.8064980166883251 and parameters: {'n_estimators': 2070, 'max_depth': 2, 'learning_rate': 0.07256187027444631, 'subsample': 0.7616761307388931, 'reg_alpha': 0.6253262226109154, 'reg_lambda': 0.8467858747072465, 'colsample_bytree': 0.537729936119458, 'min_child_samples': 11}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:18:35,641]\u001b[0m Trial 47 finished with value: 0.8010838872227163 and parameters: {'n_estimators': 3288, 'max_depth': 3, 'learning_rate': 0.07184785389772193, 'subsample': 0.7717386009428316, 'reg_alpha': 0.6390868021743616, 'reg_lambda': 0.8544060060275558, 'colsample_bytree': 0.5221643142999041, 'min_child_samples': 11}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:18:42,417]\u001b[0m Trial 48 finished with value: 0.7903738275294405 and parameters: {'n_estimators': 2838, 'max_depth': 1, 'learning_rate': 0.0641859713753704, 'subsample': 0.7698686985598565, 'reg_alpha': 0.6943757510593253, 'reg_lambda': 0.9388740624548411, 'colsample_bytree': 0.5668323035110672, 'min_child_samples': 9}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\lightgbm\\sklearn.py:736: UserWarning: 'verbose' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'verbose' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
      "\u001b[32m[I 2023-07-29 00:19:11,063]\u001b[0m Trial 49 finished with value: 0.7958923259960089 and parameters: {'n_estimators': 2576, 'max_depth': 7, 'learning_rate': 0.06830099177688066, 'subsample': 0.7374364430261706, 'reg_alpha': 0.7463303877323503, 'reg_lambda': 0.8166998914525836, 'colsample_bytree': 0.541424282644691, 'min_child_samples': 8}. Best is trial 16 with value: 0.8082354163850255.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 00:19:11,075]\u001b[0m A new study created in memory with name: no-name-6909fe8e-317e-455b-a3c5-24eb84c9ccc1\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM - Best Hyperparameters: {'n_estimators': 2822, 'max_depth': 2, 'learning_rate': 0.07289267457871532, 'subsample': 0.8362101731189066, 'reg_alpha': 0.5294708841147577, 'reg_lambda': 0.8180626444557617, 'colsample_bytree': 0.572137249155041, 'min_child_samples': 20}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 00:21:39,969]\u001b[0m Trial 0 finished with value: 0.7918607812795821 and parameters: {'n_estimators': 758, 'max_depth': 9, 'learning_rate': 0.06394352409361831, 'subsample': 0.7974306436006662, 'rsm': 0.8053398332099841, 'reg_lambda': 0.004108800361967702, 'random_strength': 6}. Best is trial 0 with value: 0.7918607812795821.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 00:28:14,758]\u001b[0m Trial 1 finished with value: 0.79215273040817 and parameters: {'n_estimators': 4608, 'max_depth': 8, 'learning_rate': 0.05217007795976401, 'subsample': 0.6723470448363513, 'rsm': 0.5108948286430401, 'reg_lambda': 0.4837234840018284, 'random_strength': 5}. Best is trial 1 with value: 0.79215273040817.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 00:36:32,387]\u001b[0m Trial 2 finished with value: 0.7943666155712614 and parameters: {'n_estimators': 3787, 'max_depth': 9, 'learning_rate': 0.014760094086431759, 'subsample': 0.671894374852553, 'rsm': 0.5320676758023126, 'reg_lambda': 0.7031557085839208, 'random_strength': 8}. Best is trial 2 with value: 0.7943666155712614.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 00:41:33,689]\u001b[0m Trial 3 finished with value: 0.8028824192378269 and parameters: {'n_estimators': 4849, 'max_depth': 7, 'learning_rate': 0.008265820477250345, 'subsample': 0.9448353055843955, 'rsm': 0.8185944289363574, 'reg_lambda': 0.03190587174321724, 'random_strength': 2}. Best is trial 3 with value: 0.8028824192378269.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 00:42:00,538]\u001b[0m Trial 4 finished with value: 0.7713735548514664 and parameters: {'n_estimators': 3351, 'max_depth': 1, 'learning_rate': 0.02517329165346546, 'subsample': 0.8620677277247124, 'rsm': 0.5895608518288157, 'reg_lambda': 0.38868178918481666, 'random_strength': 2}. Best is trial 3 with value: 0.8028824192378269.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 00:43:30,930]\u001b[0m Trial 5 finished with value: 0.7961317845313793 and parameters: {'n_estimators': 4386, 'max_depth': 4, 'learning_rate': 0.0813036868473972, 'subsample': 0.9203371595631664, 'rsm': 0.6193957241795336, 'reg_lambda': 0.5483375657727861, 'random_strength': 3}. Best is trial 3 with value: 0.8028824192378269.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 00:44:29,867]\u001b[0m Trial 6 finished with value: 0.8091990600422825 and parameters: {'n_estimators': 4463, 'max_depth': 3, 'learning_rate': 0.029866552303159634, 'subsample': 0.546862041805392, 'rsm': 0.8347600081013551, 'reg_lambda': 0.021204208918002787, 'random_strength': 2}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 00:44:34,368]\u001b[0m Trial 7 finished with value: 0.6680099029153757 and parameters: {'n_estimators': 201, 'max_depth': 4, 'learning_rate': 0.013613574920022657, 'subsample': 0.9691321166976412, 'rsm': 0.9333815542824087, 'reg_lambda': 0.8841665448723933, 'random_strength': 8}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 00:45:25,763]\u001b[0m Trial 8 finished with value: 0.8050987508201584 and parameters: {'n_estimators': 1894, 'max_depth': 5, 'learning_rate': 0.05274500226795839, 'subsample': 0.8637447827003208, 'rsm': 0.8016070085091336, 'reg_lambda': 0.9816884119336929, 'random_strength': 8}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 00:47:50,267]\u001b[0m Trial 9 finished with value: 0.7993344095524885 and parameters: {'n_estimators': 4088, 'max_depth': 6, 'learning_rate': 0.041480712256281235, 'subsample': 0.8904489832706031, 'rsm': 0.9916290904513639, 'reg_lambda': 0.5796277996063537, 'random_strength': 3}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 00:48:10,588]\u001b[0m Trial 10 finished with value: 0.7947229106831151 and parameters: {'n_estimators': 2747, 'max_depth': 1, 'learning_rate': 0.09390658777748764, 'subsample': 0.5187386088207542, 'rsm': 0.7010516537553043, 'reg_lambda': 0.20552306912805507, 'random_strength': 1}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 00:48:39,824]\u001b[0m Trial 11 finished with value: 0.8063668267931361 and parameters: {'n_estimators': 1673, 'max_depth': 4, 'learning_rate': 0.038198651869213805, 'subsample': 0.50114085755339, 'rsm': 0.8615742621545773, 'reg_lambda': 0.9765955927646345, 'random_strength': 10}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 00:49:00,974]\u001b[0m Trial 12 finished with value: 0.8020573780251271 and parameters: {'n_estimators': 1589, 'max_depth': 3, 'learning_rate': 0.03242871670786628, 'subsample': 0.5078756999467399, 'rsm': 0.8945828008086028, 'reg_lambda': 0.7797578583869152, 'random_strength': 10}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 00:49:33,035]\u001b[0m Trial 13 finished with value: 0.8052553799159587 and parameters: {'n_estimators': 2398, 'max_depth': 3, 'learning_rate': 0.03218288947786792, 'subsample': 0.5719153234500346, 'rsm': 0.8784052069452724, 'reg_lambda': 0.9970136446205277, 'random_strength': 5}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 00:49:46,334]\u001b[0m Trial 14 finished with value: 0.7765734452044579 and parameters: {'n_estimators': 1299, 'max_depth': 2, 'learning_rate': 0.023596365521881588, 'subsample': 0.5861683640020651, 'rsm': 0.7207689438504299, 'reg_lambda': 0.2873362275480307, 'random_strength': 10}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 00:50:52,653]\u001b[0m Trial 15 finished with value: 0.7853340737660579 and parameters: {'n_estimators': 2837, 'max_depth': 5, 'learning_rate': 0.005072085048640252, 'subsample': 0.5019882553782655, 'rsm': 0.8628886093675812, 'reg_lambda': 0.6761031188522606, 'random_strength': 6}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 00:51:22,814]\u001b[0m Trial 16 finished with value: 0.6067114794590637 and parameters: {'n_estimators': 2142, 'max_depth': 3, 'learning_rate': 0.0007408135704089283, 'subsample': 0.6113940294005749, 'rsm': 0.7528579570185452, 'reg_lambda': 0.17195241838227268, 'random_strength': 4}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 00:53:24,407]\u001b[0m Trial 17 finished with value: 0.7978625688644887 and parameters: {'n_estimators': 3574, 'max_depth': 6, 'learning_rate': 0.04251498234368268, 'subsample': 0.6600148254021373, 'rsm': 0.9497349842594063, 'reg_lambda': 0.40872015842178555, 'random_strength': 7}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 00:53:44,831]\u001b[0m Trial 18 finished with value: 0.8086937971861634 and parameters: {'n_estimators': 1062, 'max_depth': 4, 'learning_rate': 0.06355729251711226, 'subsample': 0.7346088695339675, 'rsm': 0.8375609560009546, 'reg_lambda': 0.8210297325369516, 'random_strength': 9}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 00:53:46,815]\u001b[0m Trial 19 finished with value: 0.7311838179131112 and parameters: {'n_estimators': 156, 'max_depth': 2, 'learning_rate': 0.061666486143505304, 'subsample': 0.7321807362746272, 'rsm': 0.7521222616972607, 'reg_lambda': 0.819461374571775, 'random_strength': 1}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 00:57:52,259]\u001b[0m Trial 20 finished with value: 0.7837705669117065 and parameters: {'n_estimators': 779, 'max_depth': 10, 'learning_rate': 0.06513632027275224, 'subsample': 0.7841786457982087, 'rsm': 0.8139961363312597, 'reg_lambda': 0.618413489701249, 'random_strength': 9}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 00:58:13,160]\u001b[0m Trial 21 finished with value: 0.8038981551481372 and parameters: {'n_estimators': 1145, 'max_depth': 4, 'learning_rate': 0.03649886997774228, 'subsample': 0.5414955975193187, 'rsm': 0.8579841952065034, 'reg_lambda': 0.8664414571531509, 'random_strength': 9}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 00:58:42,050]\u001b[0m Trial 22 finished with value: 0.8084288388954142 and parameters: {'n_estimators': 1658, 'max_depth': 4, 'learning_rate': 0.045945414297864126, 'subsample': 0.5690163310505083, 'rsm': 0.9108350526657705, 'reg_lambda': 0.7568165553426711, 'random_strength': 10}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 00:59:14,811]\u001b[0m Trial 23 finished with value: 0.8084776700799995 and parameters: {'n_estimators': 3125, 'max_depth': 2, 'learning_rate': 0.046850251244509394, 'subsample': 0.6166058083712999, 'rsm': 0.922218501706225, 'reg_lambda': 0.6815992933659858, 'random_strength': 9}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 00:59:48,838]\u001b[0m Trial 24 finished with value: 0.8062425186512319 and parameters: {'n_estimators': 3217, 'max_depth': 2, 'learning_rate': 0.0514543843889448, 'subsample': 0.6260589466167392, 'rsm': 0.9748034205553712, 'reg_lambda': 0.6654058371221098, 'random_strength': 7}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 01:00:35,769]\u001b[0m Trial 25 finished with value: 0.8035780446936549 and parameters: {'n_estimators': 4240, 'max_depth': 2, 'learning_rate': 0.07191281558277843, 'subsample': 0.7191953094721653, 'rsm': 0.9361897757500047, 'reg_lambda': 0.5107166309149778, 'random_strength': 9}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 01:01:00,100]\u001b[0m Trial 26 finished with value: 0.7908448726998029 and parameters: {'n_estimators': 2991, 'max_depth': 1, 'learning_rate': 0.05547387645819496, 'subsample': 0.6351397051055037, 'rsm': 0.9169187216616614, 'reg_lambda': 0.6189611931045294, 'random_strength': 4}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 01:01:53,804]\u001b[0m Trial 27 finished with value: 0.8019761805393325 and parameters: {'n_estimators': 3888, 'max_depth': 3, 'learning_rate': 0.04683411182431614, 'subsample': 0.6968827868206607, 'rsm': 0.9682585717322322, 'reg_lambda': 0.727977437605245, 'random_strength': 7}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 01:03:47,761]\u001b[0m Trial 28 finished with value: 0.8019710920036245 and parameters: {'n_estimators': 4738, 'max_depth': 5, 'learning_rate': 0.07484111532239295, 'subsample': 0.5935666272059864, 'rsm': 0.9044650463686287, 'reg_lambda': 0.817234312996586, 'random_strength': 9}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 01:04:22,457]\u001b[0m Trial 29 finished with value: 0.8063682905161746 and parameters: {'n_estimators': 2414, 'max_depth': 3, 'learning_rate': 0.05977938523500012, 'subsample': 0.7696768378092963, 'rsm': 0.9954639988040596, 'reg_lambda': 0.049984517213232105, 'random_strength': 6}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 01:04:29,616]\u001b[0m Trial 30 finished with value: 0.7774172860069372 and parameters: {'n_estimators': 672, 'max_depth': 2, 'learning_rate': 0.04616806521332356, 'subsample': 0.5533003812907624, 'rsm': 0.8370580440056689, 'reg_lambda': 0.644242999722985, 'random_strength': 8}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 01:04:48,118]\u001b[0m Trial 31 finished with value: 0.8084053058296754 and parameters: {'n_estimators': 1066, 'max_depth': 4, 'learning_rate': 0.04770187008877604, 'subsample': 0.5557158973312132, 'rsm': 0.906742221256165, 'reg_lambda': 0.7511408246885314, 'random_strength': 10}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 01:05:33,353]\u001b[0m Trial 32 finished with value: 0.8074667858764147 and parameters: {'n_estimators': 1907, 'max_depth': 5, 'learning_rate': 0.05692500348541836, 'subsample': 0.5886880577085938, 'rsm': 0.8858205689292903, 'reg_lambda': 0.7300078258720553, 'random_strength': 9}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 01:06:12,889]\u001b[0m Trial 33 finished with value: 0.8036149937019741 and parameters: {'n_estimators': 761, 'max_depth': 7, 'learning_rate': 0.0445306419571794, 'subsample': 0.6382173639461826, 'rsm': 0.9445302543301319, 'reg_lambda': 0.6944238732534231, 'random_strength': 10}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 01:06:34,480]\u001b[0m Trial 34 finished with value: 0.8068348033408321 and parameters: {'n_estimators': 1512, 'max_depth': 3, 'learning_rate': 0.05485004683881625, 'subsample': 0.6858131374881502, 'rsm': 0.8384619123297783, 'reg_lambda': 0.5394499628632519, 'random_strength': 8}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 01:07:13,436]\u001b[0m Trial 35 finished with value: 0.8065893017744957 and parameters: {'n_estimators': 2105, 'max_depth': 4, 'learning_rate': 0.02573973467548908, 'subsample': 0.6563343925469708, 'rsm': 0.7828018583173451, 'reg_lambda': 0.46288036807930355, 'random_strength': 7}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 01:09:48,360]\u001b[0m Trial 36 finished with value: 0.7975139871572491 and parameters: {'n_estimators': 4539, 'max_depth': 6, 'learning_rate': 0.0657241125670213, 'subsample': 0.6149258766550277, 'rsm': 0.8403839608740368, 'reg_lambda': 0.5964910789250919, 'random_strength': 4}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 01:10:16,821]\u001b[0m Trial 37 finished with value: 0.791077059391556 and parameters: {'n_estimators': 3662, 'max_depth': 1, 'learning_rate': 0.049921131762078824, 'subsample': 0.5374991918531241, 'rsm': 0.913480329527481, 'reg_lambda': 0.010222982971159644, 'random_strength': 2}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 01:10:52,060]\u001b[0m Trial 38 finished with value: 0.7892788789889238 and parameters: {'n_estimators': 381, 'max_depth': 8, 'learning_rate': 0.03913430808776053, 'subsample': 0.7472105758880052, 'rsm': 0.8848252826176589, 'reg_lambda': 0.6988634121339465, 'random_strength': 9}. Best is trial 6 with value: 0.8091990600422825.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 01:12:16,006]\u001b[0m Trial 39 finished with value: 0.8093989426275512 and parameters: {'n_estimators': 4901, 'max_depth': 4, 'learning_rate': 0.018812193862372664, 'subsample': 0.5701092869059072, 'rsm': 0.7857242286786702, 'reg_lambda': 0.773020178734695, 'random_strength': 3}. Best is trial 39 with value: 0.8093989426275512.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 01:14:24,638]\u001b[0m Trial 40 finished with value: 0.8073841701312152 and parameters: {'n_estimators': 4864, 'max_depth': 5, 'learning_rate': 0.011640676681778442, 'subsample': 0.8180958934822355, 'rsm': 0.7956924783849645, 'reg_lambda': 0.9229746607087349, 'random_strength': 3}. Best is trial 39 with value: 0.8093989426275512.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 01:15:49,923]\u001b[0m Trial 41 finished with value: 0.8090150131802033 and parameters: {'n_estimators': 4969, 'max_depth': 4, 'learning_rate': 0.018345784022263133, 'subsample': 0.5672724507111369, 'rsm': 0.7829761494535894, 'reg_lambda': 0.7873220534993959, 'random_strength': 2}. Best is trial 39 with value: 0.8093989426275512.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 01:16:52,892]\u001b[0m Trial 42 finished with value: 0.8063046734752708 and parameters: {'n_estimators': 4913, 'max_depth': 3, 'learning_rate': 0.020458228444855613, 'subsample': 0.5309194751816757, 'rsm': 0.7808307924626149, 'reg_lambda': 0.8043091440991803, 'random_strength': 2}. Best is trial 39 with value: 0.8093989426275512.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 01:18:11,479]\u001b[0m Trial 43 finished with value: 0.8077505484472423 and parameters: {'n_estimators': 4502, 'max_depth': 4, 'learning_rate': 0.016957768267420455, 'subsample': 0.6013930719303753, 'rsm': 0.8218836035635902, 'reg_lambda': 0.8459943894281956, 'random_strength': 1}. Best is trial 39 with value: 0.8093989426275512.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 01:19:01,762]\u001b[0m Trial 44 finished with value: 0.8074725639897081 and parameters: {'n_estimators': 4999, 'max_depth': 2, 'learning_rate': 0.027640240112924996, 'subsample': 0.5685550924084835, 'rsm': 0.801875278580209, 'reg_lambda': 0.9075535344490308, 'random_strength': 2}. Best is trial 39 with value: 0.8093989426275512.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 01:20:10,850]\u001b[0m Trial 45 finished with value: 0.8081720253134721 and parameters: {'n_estimators': 4071, 'max_depth': 4, 'learning_rate': 0.018686612120725195, 'subsample': 0.5308162632447672, 'rsm': 0.7656137323319409, 'reg_lambda': 0.8011263857197282, 'random_strength': 3}. Best is trial 39 with value: 0.8093989426275512.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 01:21:09,537]\u001b[0m Trial 46 finished with value: 0.8018214982187607 and parameters: {'n_estimators': 4241, 'max_depth': 3, 'learning_rate': 0.01188067343403654, 'subsample': 0.5822152038516702, 'rsm': 0.7376196633750972, 'reg_lambda': 0.776294515791144, 'random_strength': 2}. Best is trial 39 with value: 0.8093989426275512.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 01:23:03,483]\u001b[0m Trial 47 finished with value: 0.8074744511996608 and parameters: {'n_estimators': 4719, 'max_depth': 5, 'learning_rate': 0.021989634222454917, 'subsample': 0.6417753225690979, 'rsm': 0.6975564195511637, 'reg_lambda': 0.8566193206569038, 'random_strength': 1}. Best is trial 39 with value: 0.8093989426275512.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 01:24:58,898]\u001b[0m Trial 48 finished with value: 0.8076737660040602 and parameters: {'n_estimators': 3373, 'max_depth': 6, 'learning_rate': 0.017583024393364684, 'subsample': 0.6093604736758588, 'rsm': 0.8201897680024379, 'reg_lambda': 0.5592624665180438, 'random_strength': 5}. Best is trial 39 with value: 0.8093989426275512.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 01:25:33,013]\u001b[0m Trial 49 finished with value: 0.7826012390982756 and parameters: {'n_estimators': 4407, 'max_depth': 1, 'learning_rate': 0.029965187444945196, 'subsample': 0.5576833342579371, 'rsm': 0.8699258690605345, 'reg_lambda': 0.717446575120248, 'random_strength': 3}. Best is trial 39 with value: 0.8093989426275512.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 01:25:33,013]\u001b[0m A new study created in memory with name: no-name-21c69c5e-6616-41d3-8db2-1724288d9214\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CatBoost - Best Hyperparameters: {'n_estimators': 4901, 'max_depth': 4, 'learning_rate': 0.018812193862372664, 'subsample': 0.5701092869059072, 'rsm': 0.7857242286786702, 'reg_lambda': 0.773020178734695, 'random_strength': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-07-29 01:37:24,814]\u001b[0m Trial 0 finished with value: 0.8002251402564684 and parameters: {'n_estimators': 4299, 'max_depth': 4, 'learning_rate': 0.04317902306492365, 'subsample': 0.6648683873318781, 'reg_alpha': 0.2164527111382445, 'reg_lambda': 0.5239512937736286, 'gamma': 0.44386097124128576, 'min_child_weight': 8}. Best is trial 0 with value: 0.8002251402564684.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 01:56:16,323]\u001b[0m Trial 1 finished with value: 0.7946823087742512 and parameters: {'n_estimators': 4826, 'max_depth': 6, 'learning_rate': 0.0965733048024456, 'subsample': 0.594378118405551, 'reg_alpha': 0.4769904690017993, 'reg_lambda': 0.355800610652114, 'gamma': 0.7850590364439346, 'min_child_weight': 1}. Best is trial 0 with value: 0.8002251402564684.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 02:06:21,383]\u001b[0m Trial 2 finished with value: 0.7970455763511575 and parameters: {'n_estimators': 4029, 'max_depth': 3, 'learning_rate': 0.00759635795398872, 'subsample': 0.8902946132548588, 'reg_alpha': 0.2325148031313874, 'reg_lambda': 0.27740765498096265, 'gamma': 0.26648667026484285, 'min_child_weight': 7}. Best is trial 0 with value: 0.8002251402564684.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 02:15:59,305]\u001b[0m Trial 3 finished with value: 0.7909222976794398 and parameters: {'n_estimators': 1792, 'max_depth': 8, 'learning_rate': 0.023772202599629404, 'subsample': 0.5973791170404695, 'reg_alpha': 0.2646358224408417, 'reg_lambda': 0.91860961318664, 'gamma': 0.5191743482887891, 'min_child_weight': 9}. Best is trial 0 with value: 0.8002251402564684.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 02:16:56,996]\u001b[0m Trial 4 finished with value: 0.7468094394657498 and parameters: {'n_estimators': 1322, 'max_depth': 1, 'learning_rate': 0.024060709215316837, 'subsample': 0.5046154002334502, 'reg_alpha': 0.1242199561639643, 'reg_lambda': 0.8646525723852178, 'gamma': 0.91422589267206, 'min_child_weight': 1}. Best is trial 0 with value: 0.8002251402564684.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 02:26:18,796]\u001b[0m Trial 5 finished with value: 0.7991461085393085 and parameters: {'n_estimators': 3513, 'max_depth': 3, 'learning_rate': 0.05070940906923817, 'subsample': 0.9371246675647447, 'reg_alpha': 0.8867202462801212, 'reg_lambda': 0.5837512117668188, 'gamma': 0.7003071148967397, 'min_child_weight': 6}. Best is trial 0 with value: 0.8002251402564684.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 02:34:22,911]\u001b[0m Trial 6 finished with value: 0.8039964862814032 and parameters: {'n_estimators': 2713, 'max_depth': 5, 'learning_rate': 0.008811585627593823, 'subsample': 0.5307165045453816, 'reg_alpha': 0.9587814870429702, 'reg_lambda': 0.34306966334630296, 'gamma': 0.18869787682536276, 'min_child_weight': 8}. Best is trial 6 with value: 0.8039964862814032.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 02:36:02,476]\u001b[0m Trial 7 finished with value: 0.7988933770229332 and parameters: {'n_estimators': 633, 'max_depth': 3, 'learning_rate': 0.05851351965361786, 'subsample': 0.917852500215816, 'reg_alpha': 0.1246737521383825, 'reg_lambda': 0.9798424358995304, 'gamma': 0.22607688657466307, 'min_child_weight': 5}. Best is trial 6 with value: 0.8039964862814032.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 02:42:27,639]\u001b[0m Trial 8 finished with value: 0.8019858618923945 and parameters: {'n_estimators': 4297, 'max_depth': 2, 'learning_rate': 0.03921810023307731, 'subsample': 0.7372266626109065, 'reg_alpha': 0.5258145129856464, 'reg_lambda': 0.9057836512048486, 'gamma': 0.35411240042938186, 'min_child_weight': 2}. Best is trial 6 with value: 0.8039964862814032.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 02:56:41,931]\u001b[0m Trial 9 finished with value: 0.7955920015791953 and parameters: {'n_estimators': 4955, 'max_depth': 4, 'learning_rate': 0.0577609945383666, 'subsample': 0.7110988620527003, 'reg_alpha': 0.9648424218657498, 'reg_lambda': 0.6482126625577703, 'gamma': 0.7223120951363137, 'min_child_weight': 7}. Best is trial 6 with value: 0.8039964862814032.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 03:19:27,321]\u001b[0m Trial 10 finished with value: 0.7778434165008479 and parameters: {'n_estimators': 2639, 'max_depth': 10, 'learning_rate': 0.0029828023915799565, 'subsample': 0.8189754082638735, 'reg_alpha': 0.7985370544183683, 'reg_lambda': 0.027913890397058883, 'gamma': 0.0008399944395740544, 'min_child_weight': 10}. Best is trial 6 with value: 0.8039964862814032.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 03:21:58,950]\u001b[0m Trial 11 finished with value: 0.7699559385465877 and parameters: {'n_estimators': 3113, 'max_depth': 1, 'learning_rate': 0.023762788271581556, 'subsample': 0.7748875371665606, 'reg_alpha': 0.7327448983025, 'reg_lambda': 0.7440596294948777, 'gamma': 0.22371968952818366, 'min_child_weight': 4}. Best is trial 6 with value: 0.8039964862814032.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 03:33:44,721]\u001b[0m Trial 12 finished with value: 0.7924478080405987 and parameters: {'n_estimators': 2091, 'max_depth': 6, 'learning_rate': 0.036835552277700745, 'subsample': 0.9954729234205559, 'reg_alpha': 0.6331617926949945, 'reg_lambda': 0.7833421071669889, 'gamma': 0.04651156742086332, 'min_child_weight': 3}. Best is trial 6 with value: 0.8039964862814032.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 04:01:47,253]\u001b[0m Trial 13 finished with value: 0.7880165310019983 and parameters: {'n_estimators': 3321, 'max_depth': 8, 'learning_rate': 0.002573214467285062, 'subsample': 0.806607503631074, 'reg_alpha': 0.9715042455889066, 'reg_lambda': 0.4133751496723744, 'gamma': 0.3786993008235567, 'min_child_weight': 3}. Best is trial 6 with value: 0.8039964862814032.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 04:02:34,709]\u001b[0m Trial 14 finished with value: 0.7647243814455817 and parameters: {'n_estimators': 212, 'max_depth': 5, 'learning_rate': 0.01583005103109926, 'subsample': 0.5035482811210445, 'reg_alpha': 0.5356823313928007, 'reg_lambda': 0.7131898291976294, 'gamma': 0.14079896142993925, 'min_child_weight': 10}. Best is trial 6 with value: 0.8039964862814032.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 04:07:50,748]\u001b[0m Trial 15 finished with value: 0.8032414052198211 and parameters: {'n_estimators': 2621, 'max_depth': 2, 'learning_rate': 0.035237861202402194, 'subsample': 0.6978596232698312, 'reg_alpha': 0.4282264299355085, 'reg_lambda': 0.8395324801328834, 'gamma': 0.3694116607097852, 'min_child_weight': 2}. Best is trial 6 with value: 0.8039964862814032.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 04:24:21,765]\u001b[0m Trial 16 finished with value: 0.7966615528783882 and parameters: {'n_estimators': 2614, 'max_depth': 7, 'learning_rate': 0.014035561442131042, 'subsample': 0.6464423252614591, 'reg_alpha': 0.3843588474012508, 'reg_lambda': 0.589829977257379, 'gamma': 0.5215828085404293, 'min_child_weight': 5}. Best is trial 6 with value: 0.8039964862814032.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 04:30:23,468]\u001b[0m Trial 17 finished with value: 0.8018764667511062 and parameters: {'n_estimators': 1515, 'max_depth': 5, 'learning_rate': 0.030759177616258317, 'subsample': 0.5877598483453151, 'reg_alpha': 0.6965843605131229, 'reg_lambda': 0.9941323527443784, 'gamma': 0.09598226242595931, 'min_child_weight': 8}. Best is trial 6 with value: 0.8039964862814032.\u001b[0m\n",
      "\u001b[32m[I 2023-07-29 04:34:29,784]\u001b[0m Trial 18 finished with value: 0.7891524801920731 and parameters: {'n_estimators': 2200, 'max_depth': 2, 'learning_rate': 0.013887960156755415, 'subsample': 0.6850324656744236, 'reg_alpha': 0.8282031410421029, 'reg_lambda': 0.5103016233093518, 'gamma': 0.14432567482040753, 'min_child_weight': 6}. Best is trial 6 with value: 0.8039964862814032.\u001b[0m\n",
      "\u001b[33m[W 2023-07-29 05:00:58,483]\u001b[0m Trial 19 failed with parameters: {'n_estimators': 2928, 'max_depth': 10, 'learning_rate': 0.00251031113120351, 'subsample': 0.7432929861760696, 'reg_alpha': 0.00851729423224945, 'reg_lambda': 0.8209482677814852, 'gamma': 0.2907942701471419, 'min_child_weight': 4} because of the following error: KeyboardInterrupt().\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\Moch Riyadh Zahran\\AppData\\Local\\Temp\\ipykernel_5408\\1044521235.py\", line 48, in objective_xgb\n",
      "    model.fit(X_train, y_train, verbose=False)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\", line 1025, in fit\n",
      "    self._Booster = train(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 620, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\", line 185, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 1918, in update\n",
      "    _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m[W 2023-07-29 05:00:58,631]\u001b[0m Trial 19 failed with value None.\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5408\\1044521235.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;31m# Optimasi menggunakan Optuna untuk XGBoost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m \u001b[0mbest_xgb_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimize_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective_xgb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'XGBoost - Best Hyperparameters:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_xgb_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5408\\1044521235.py\u001b[0m in \u001b[0;36moptimize_model\u001b[1;34m(objective, n_trials)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0moptimize_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'maximize'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Menggunakan 'minimize' untuk mencari MSE terkecil\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m     \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m     \u001b[0mbest_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\optuna\\study\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \"\"\"\n\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m         _optimize(\n\u001b[0m\u001b[0;32m    426\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m             _optimize_sequential(\n\u001b[0m\u001b[0;32m     67\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m             \u001b[1;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     ):\n\u001b[1;32m--> 251\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    252\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\optuna\\study\\_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    198\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 200\u001b[1;33m             \u001b[0mvalue_or_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    201\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m             \u001b[1;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_5408\\1044521235.py\u001b[0m in \u001b[0;36mobjective_xgb\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     46\u001b[0m     }\n\u001b[0;32m     47\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[0;32m   1023\u001b[0m                 \u001b[0mxgb_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_metric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mearly_stopping_rounds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1024\u001b[0m             )\n\u001b[1;32m-> 1025\u001b[1;33m             self._Booster = train(\n\u001b[0m\u001b[0;32m   1026\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1027\u001b[0m                 \u001b[0mtrain_dmatrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    618\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    619\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 620\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    622\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbefore_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mbst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcb_container\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   1916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1917\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1919\u001b[0m                                                     \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1920\u001b[0m                                                     dtrain.handle))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "xgb_params = {\n",
    "    'n_estimators': (100, 5000),\n",
    "    'max_depth': (1, 10),\n",
    "    'learning_rate': (0.0001, 0.1),\n",
    "    'subsample': (0.5, 1),\n",
    "    'reg_alpha': (0, 1),\n",
    "    'reg_lambda': (0, 1),\n",
    "    'gamma': (0, 1),\n",
    "    'min_child_weight': (1, 10)\n",
    "}\n",
    "\n",
    "catboost_params = {\n",
    "    'n_estimators': (100, 5000),\n",
    "    'max_depth': (1, 10),\n",
    "    'learning_rate': (0.0001, 0.1),\n",
    "    'subsample': (0.5, 1),\n",
    "    'rsm': (0.5, 1),\n",
    "    'reg_lambda': (0, 1),\n",
    "    'random_strength': (1, 10)\n",
    "}\n",
    "\n",
    "lgb_params = {\n",
    "    'n_estimators': (100, 5000),\n",
    "    'max_depth': (1, 10),\n",
    "    'learning_rate': (0.0001, 0.1),\n",
    "    'subsample': (0.5, 1),\n",
    "    'reg_alpha': (0, 1),\n",
    "    'reg_lambda': (0, 1),\n",
    "    'colsample_bytree': (0.5, 1),\n",
    "    'min_child_samples': (1, 20)\n",
    "}\n",
    "\n",
    "\n",
    "def objective_xgb(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', *xgb_params['n_estimators']),\n",
    "        'max_depth': trial.suggest_int('max_depth', *xgb_params['max_depth']),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', *xgb_params['learning_rate']),\n",
    "        'subsample': trial.suggest_float('subsample', *xgb_params['subsample']),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', *xgb_params['reg_alpha']),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', *xgb_params['reg_lambda']),\n",
    "        'gamma': trial.suggest_float('gamma', *xgb_params['gamma']),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', *xgb_params['min_child_weight'])\n",
    "    }\n",
    "    model = xgb.XGBRegressor(**params)\n",
    "    model.fit(X_train, y_train, verbose=False)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = r2_score(y_test, y_pred)\n",
    "    return mse\n",
    "\n",
    "def objective_catboost(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', *catboost_params['n_estimators']),\n",
    "        'max_depth': trial.suggest_int('max_depth', *catboost_params['max_depth']),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', *catboost_params['learning_rate']),\n",
    "        'subsample': trial.suggest_float('subsample', *catboost_params['subsample']),\n",
    "        'rsm': trial.suggest_float('rsm', *catboost_params['rsm']),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', *catboost_params['reg_lambda']),\n",
    "        'random_strength': trial.suggest_int('random_strength', *catboost_params['random_strength'])\n",
    "    }\n",
    "    model = CatBoostRegressor(**params)\n",
    "    model.fit(X_train, y_train, verbose=False)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = r2_score(y_test, y_pred)\n",
    "    return mse\n",
    "\n",
    "def objective_lgb(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', *lgb_params['n_estimators']),\n",
    "        'max_depth': trial.suggest_int('max_depth', *lgb_params['max_depth']),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', *lgb_params['learning_rate']),\n",
    "        'subsample': trial.suggest_float('subsample', *lgb_params['subsample']),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', *lgb_params['reg_alpha']),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', *lgb_params['reg_lambda']),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', *lgb_params['colsample_bytree']),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', *lgb_params['min_child_samples'])\n",
    "    }\n",
    "    model = lgb.LGBMRegressor(**params)\n",
    "    model.fit(X_train, y_train, verbose=False)\n",
    "    y_pred = model.predict(X_test)\n",
    "    mse = r2_score(y_test, y_pred)\n",
    "    return mse\n",
    "\n",
    "def optimize_model(objective, n_trials):\n",
    "    study = optuna.create_study(direction='maximize')  # Menggunakan 'minimize' untuk mencari MSE terkecil\n",
    "    study.optimize(objective, n_trials=n_trials)\n",
    "    best_params = study.best_params\n",
    "    return best_params\n",
    "\n",
    "best_lgb_params = optimize_model(objective_lgb, n_trials=50)\n",
    "print('LightGBM - Best Hyperparameters:', best_lgb_params)\n",
    "\n",
    "best_catboost_params = optimize_model(objective_catboost, n_trials=50)\n",
    "print('CatBoost - Best Hyperparameters:', best_catboost_params)\n",
    "\n",
    "best_xgb_params = optimize_model(objective_xgb, n_trials=50)\n",
    "print('XGBoost - Best Hyperparameters:', best_xgb_params)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
